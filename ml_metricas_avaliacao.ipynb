{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "📊 Métricas de Avaliação de Modelos de Classificação\n",
        "Acurácia, precisão, sensibilidade, especificidade e F1-score são métricas fundamentais para avaliar o desempenho de modelos de classificação. Elas medem diferentes aspectos dos acertos e erros das previsões, ajudando a entender se o modelo está funcionando como esperado.\n",
        "\n",
        "🧩 Conceitos Iniciais: Matriz de Confusão\n",
        "Antes de entender as métricas, é essencial compreender os elementos da matriz de confusão:\n",
        "\n",
        "Termo\tDefinição\n",
        "VP (Verdadeiro Positivo)\tO modelo previu positivo corretamente\n",
        "VN (Verdadeiro Negativo)\tO modelo previu negativo corretamente\n",
        "FP (Falso Positivo)\tO modelo previu positivo, mas era negativo\n",
        "FN (Falso Negativo)\tO modelo previu negativo, mas era positivo\n",
        "\n",
        "🔗 Entenda a Matriz de Confusão - scikit-learn\n",
        "\n",
        "✅ Acurácia\n",
        "Definição: Proporção de acertos (VP + VN) sobre o total de previsões.\n",
        "\n",
        "Acur\n",
        "a\n",
        "ˊ\n",
        "cia\n",
        "=\n",
        "𝑉\n",
        "𝑃\n",
        "+\n",
        "𝑉\n",
        "𝑁\n",
        "𝑉\n",
        "𝑃\n",
        "+\n",
        "𝑉\n",
        "𝑁\n",
        "+\n",
        "𝐹\n",
        "𝑃\n",
        "+\n",
        "𝐹\n",
        "𝑁\n",
        "Acur\n",
        "a\n",
        "ˊ\n",
        " cia=\n",
        "VP+VN+FP+FN\n",
        "VP+VN\n",
        "​\n",
        "\n",
        "📌 Útil em problemas com classes balanceadas, mas pode ser enganosa com dados desbalanceados.\n",
        "\n",
        "🔗 Accuracy Score - Scikit-learn\n",
        "\n",
        "🎯 Precisão (Precision)\n",
        "Definição: Entre as previsões positivas feitas, quantas são realmente positivas?\n",
        "\n",
        "Precis\n",
        "a\n",
        "˜\n",
        "o\n",
        "=\n",
        "𝑉\n",
        "𝑃\n",
        "𝑉\n",
        "𝑃\n",
        "+\n",
        "𝐹\n",
        "𝑃\n",
        "Precis\n",
        "a\n",
        "˜\n",
        " o=\n",
        "VP+FP\n",
        "VP\n",
        "​\n",
        "\n",
        "📌 Ideal quando falsos positivos são mais custosos (ex: alarmes falsos em diagnósticos médicos).\n",
        "\n",
        "🔗 Precision Score - Scikit-learn\n",
        "\n",
        "🔍 Sensibilidade / Recall\n",
        "Definição: Entre as amostras realmente positivas, quantas foram corretamente identificadas?\n",
        "\n",
        "Recall\n",
        "=\n",
        "𝑉\n",
        "𝑃\n",
        "𝑉\n",
        "𝑃\n",
        "+\n",
        "𝐹\n",
        "𝑁\n",
        "Recall=\n",
        "VP+FN\n",
        "VP\n",
        "​\n",
        "\n",
        "📌 Essencial quando falsos negativos são críticos (ex: detecção de doenças).\n",
        "\n",
        "🔗 Recall Score - Scikit-learn\n",
        "\n",
        "❌ Especificidade\n",
        "Definição: Mede a proporção de verdadeiros negativos corretamente classificados.\n",
        "\n",
        "Especificidade\n",
        "=\n",
        "𝑉\n",
        "𝑁\n",
        "𝑉\n",
        "𝑁\n",
        "+\n",
        "𝐹\n",
        "𝑃\n",
        "Especificidade=\n",
        "VN+FP\n",
        "VN\n",
        "​\n",
        "\n",
        "📌 Importante para avaliar a capacidade do modelo de reconhecer a classe negativa.\n",
        "\n",
        "⚖️ F1-Score\n",
        "Definição: Média harmônica entre precisão e sensibilidade (recall).\n",
        "\n",
        "F1\n",
        "=\n",
        "2\n",
        "⋅\n",
        "Precis\n",
        "a\n",
        "˜\n",
        "o\n",
        "⋅\n",
        "Recall\n",
        "Precis\n",
        "a\n",
        "˜\n",
        "o\n",
        "+\n",
        "Recall\n",
        "F1=2⋅\n",
        "Precis\n",
        "a\n",
        "˜\n",
        " o+Recall\n",
        "Precis\n",
        "a\n",
        "˜\n",
        " o⋅Recall\n",
        "​\n",
        "\n",
        "📌 Útil quando se busca equilíbrio entre precisão e recall, principalmente com dados desbalanceados.\n",
        "\n",
        "🔗 F1 Score - Scikit-learn\n",
        "\n",
        "🎯 Quando usar cada métrica?\n",
        "Métrica\tQuando usar\n",
        "Acurácia\tQuando os dados são balanceados\n",
        "Precisão\tQuando falsos positivos são mais graves\n",
        "Sensibilidade (Recall)\tQuando falsos negativos são mais graves\n",
        "Especificidade\tPara avaliar o acerto da classe negativa\n",
        "F1-Score\tQuando há desequilíbrio entre as classes e se busca equilíbrio entre FP e FN\n",
        "\n",
        "🖼️ Visual\n",
        "Para complementar, uma imagem útil:\n",
        "🔗 Matriz de Confusão e Métricas – Imagem Interativa no ML Cheatsheet\n",
        "\n",
        "📚 Leituras e Referências\n",
        "Scikit-learn: Métricas de Classificação\n",
        "\n",
        "Machine Learning Metrics - Towards Data Science\n",
        "\n",
        "Google Developers: Precision, Recall and F1\n"
      ],
      "metadata": {
        "id": "ksVNPTKcwkT-"
      },
      "id": "ksVNPTKcwkT-"
    },
    {
      "cell_type": "markdown",
      "id": "f44a9465",
      "metadata": {
        "id": "f44a9465"
      },
      "source": [
        "## 📦 Importação de Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "982b98b7",
      "metadata": {
        "id": "982b98b7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow import math, argmax\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56fad72d",
      "metadata": {
        "id": "56fad72d"
      },
      "source": [
        "## 📊 Carregamento do TensorBoard e Dataset MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9db2655b",
      "metadata": {
        "id": "9db2655b"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "logdir = 'log'\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64b73d81",
      "metadata": {
        "id": "64b73d81"
      },
      "source": [
        "## 🧼 Pré-processamento das Imagens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82f1b2a1",
      "metadata": {
        "id": "82f1b2a1"
      },
      "outputs": [],
      "source": [
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "classes = [0,1,2,3,4,5,6,7,8,9]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76120e67",
      "metadata": {
        "id": "76120e67"
      },
      "source": [
        "## 🧠 Construção do Modelo CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb442f7b",
      "metadata": {
        "id": "eb442f7b"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPool2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPool2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3462b93",
      "metadata": {
        "id": "a3462b93"
      },
      "source": [
        "## ⚙️ Compilação e Treinamento do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64361705",
      "metadata": {
        "id": "64361705"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5, validation_data=(test_images, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ced3cdf2",
      "metadata": {
        "id": "ced3cdf2"
      },
      "source": [
        "## 🔮 Predição nos Dados de Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d1cc3af",
      "metadata": {
        "id": "7d1cc3af"
      },
      "outputs": [],
      "source": [
        "y_true = test_labels\n",
        "y_pred = model.predict(test_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9783e1b",
      "metadata": {
        "id": "b9783e1b"
      },
      "source": [
        "## 📏 Matriz de Confusão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "390d1ca0",
      "metadata": {
        "id": "390d1ca0"
      },
      "outputs": [],
      "source": [
        "predicted_labels = argmax(y_pred, axis=1)\n",
        "con_mat = math.confusion_matrix(labels=y_true, predictions=predicted_labels).numpy()\n",
        "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=4)\n",
        "\n",
        "con_mat_df = pd.DataFrame(con_mat_norm, index=classes, columns=classes)\n",
        "\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(con_mat_df, annot=True, cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e429ef20",
      "metadata": {
        "id": "e429ef20"
      },
      "source": [
        "## 📈 Cálculo das Métricas por Classe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79334cb2",
      "metadata": {
        "id": "79334cb2"
      },
      "outputs": [],
      "source": [
        "tp_total = 0\n",
        "fp_total = 0\n",
        "fn_total = 0\n",
        "tn_total = 0\n",
        "\n",
        "for number_class in con_mat_df.index:\n",
        "  tp = con_mat_df.loc[number_class, number_class]\n",
        "  fp = con_mat_df.loc[:, number_class].sum() - tp\n",
        "  fn = con_mat_df.loc[number_class, :].sum() - tp\n",
        "  tn = con_mat_df.values.sum() - (tp + fp + fn)\n",
        "\n",
        "  tp_total += tp\n",
        "  fp_total += fp\n",
        "  fn_total += fn\n",
        "  tn_total += tn\n",
        "  accuracy = (tn+tp)/(tp+tn+fp+fn)\n",
        "  precision = tp/(tp+fp)\n",
        "  sensitivity = tp/(tp+fn)\n",
        "  f1_score = 2 * precision * sensitivity/(precision + sensitivity)\n",
        "  print(f\"Class {number_class}:\")\n",
        "  print(f\"  True Positives  (TP): {tp:.4f}\")\n",
        "  print(f\"  False Positives (FP): {fp:.4f}\")\n",
        "  print(f\"  False Negatives (FN): {fn:.4f}\")\n",
        "  print(f\"  True Negatives  (TN): {tn:.4f}\\n\")\n",
        "  print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "  print(f\"  Precision: {precision:.4f}\")\n",
        "  print(f\"  Sensitivity: {sensitivity:.4f}\")\n",
        "  print(f\"  F1 Score: {f1_score:.4f}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ea9370c",
      "metadata": {
        "id": "2ea9370c"
      },
      "source": [
        "## 📊 Métricas Totais (Macro Média)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2686094c",
      "metadata": {
        "id": "2686094c"
      },
      "outputs": [],
      "source": [
        "print(f\"Total:\")\n",
        "print(f\"  True Positives  (TP): {tp_total:.4f}\")\n",
        "print(f\"  False Positives (FP): {fp_total:.4f}\")\n",
        "print(f\"  False Negatives (FN): {fn_total:.4f}\")\n",
        "print(f\"  True Negatives  (TN): {tn_total:.4f}\\n\")\n",
        "print(f\"  Accuracy: {((tn_total+tp_total)/(tp_total+tn_total+fp_total+fn_total)):4f}\")\n",
        "print(f\"  Precision: {(tp_total/(tp_total+fp_total)):4f}\")\n",
        "print(f\"  Sensitivity: {(tp_total/(tp_total+fn_total)):4f}\")\n",
        "print(f\"  F1 Score: {(2 * tp_total/(2*tp_total+fp_total+fn_total)):4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}